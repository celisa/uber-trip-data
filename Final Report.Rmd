---
title: "Group Final Report - IDS 702"
author: "Elisa Chen, Ahmed Ibrahim, Genesis Qu, Pomelo Wu"
date: "`r Sys.Date()`"
output:
  pdf_document:
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(knitr)
library(caret)
library(boot)
#library(tidyverse)
library(table1)
library(pander)
library(leaps)
library(tinytex)
library(car)
#library(dplyr)
library(lattice) 
library(RColorBrewer)
panderOptions('digits', 6)
panderOptions('round', 2)
panderOptions('keep.trailing.zeros', TRUE)
# Importing packages
library(lubridate)
library(arm) 
library(caTools)
library(stargazer)
library(kableExtra)
library(caTools)
library(rmarkdown)
library(DAAG)
library(pROC)
```

## Abstract
New York City is known for heavy traffic congestion, and with the rise of ride-sharing services in the past decade, it's becoming increasingly important to understand how ride pickup services impact the traffic flow in New York City. In this report, we aim to understand whether the number of Uber pickup rides vary depending on the weather conditions, and whether Uber services increased the likelihood of traffic collision deaths in New York City. We are going to work with data on Uber pickup rides in New York City between the months January - June in 2015 as well as weather condition dataset sourced from the National Oceanic and Atmospheric Administration, which contains daily data on temperature, precipitation, snow depth, and wind strength. We also obtained data on traffic collision deaths in New York City sourced from NYPD. Based on our findings, we learned that the weather, day of the week, and Borough explain over 90% of the variation within the model. With the exception of temperature, weather conditions are less significant for determining the number of Uber pickup rides contrary to our initial belief. <POMELO TO ADD>

## Introduction
In this report, we would in particular like to research the following two questions: Q1) do weather conditions have an impact on the number of Uber pickup rides in New York City? and Q2) Did the introduction of Uber in 2015 increase the likelihood of traffic collision deaths in New York City (yes / no)? We will be building a predictive model to estimate the number of Uber rides given the weather conditions and traffic collision information on a given day to estimate how these factors influence the traffic flow in New York City. The data for Uber rides was provided by Fivethirtyeight who obtained it from NYC Taxi & Limousine Commission (TLC) (Fivethirtyeight, 2015), the weather data was obtained from the National Oceanic and Atmospheric Administration (Weather. National Oceanic and Atmospheric Administration, 2015), and the data for Traffic collisions was provided by NYPD obtained from Kaggle (NYPD, 2017).

## Methods

### Q1

#### Data
After aggregating the raw Uber data at the date and Borough level, we have 1160 observations with 50 variables. Please see appendix Table 1.1 for more details about the descriptive statistics of the dataset, and Table 1.2 for a data dictionary for the weather variables. We joined the Uber dataset with the weather dataset and aggregated at the day level for days in January - June 2015. 

```{r eda1, echo=FALSE, results='hide', message = FALSE, warnings = FALSE}
uber15 <- read_csv("https://raw.githubusercontent.com/celisa/uber-trip-data/main/uber-data-2015.csv")
uber <- read_csv("https://raw.githubusercontent.com/celisa/uber-trip-data/main/uber-data-cleaned.csv")

uber15$weekday <- wday(uber15$Pickup_date)
uber15$weekday <- 
  factor(uber15$weekday, 
         levels=c(1:7),
         labels=c("Sunday", "Monday","Tuesday",
                  "Wednesday","Thursday","Friday",
                  "Saturday"))
uber15_agg <- uber15 %>% group_by(Pickup_date, Borough, weekday) %>% 
  summarise(trips = sum(num_uber_trips))

uber_weather <- uber %>% dplyr::select(!num_uber_trips)
uber15_weather <- left_join(uber15_agg, uber_weather, by = c("Pickup_date" = "DATE"))
uber15_weather$rain <- ifelse(uber15_weather$PRCP > 0, "rain", "no_rain")
```

First thing we observe that regardless of the temperature of the day, Uber rides are significantly more popular in Manhattan than any other Borough. The number of pickups seem to remain fairly constant within a Borough with a slight increase in number of pickups during hotter days (65+Fahrenheit).

We can also see that the average number of pickups doesn't vary significantly between rainy and non-rainy days. This potentially signals that weather conditions might not be a good indicator for predicting number of pick-up rides on a given day. On the other hand, factors like Borough seem to be strongly correlated with the number of Uber pick-ups. 

```{r echo=FALSE, message = FALSE, out.width = "50%", results = "hide", fig.show='hold'}
par(mfrow = c(1, 2))
ggplot(data = uber15_weather, aes(x = TAVG, y = trips, color = Borough)) + 
  geom_point() +
  labs(x = "Tempearature (in Fahrenheit)", y = "Number of trips", title = "Temperature x Trips broken down by Boroughs")

uber15_weather$rain <- ifelse(uber15_weather$PRCP > 0, "rain", "no_rain")
ggplot(data = uber15_weather, aes(x = Borough, y = trips, color = rain)) + geom_boxplot() +
  labs(x = "Borough", y = "Number of trips", title = "How boroughs and rain impact rides (by day)") + scale_color_discrete(name = "", labels = c("No rain", "Rain"))
```

We did not observe any gaps in our weather or Uber dataset and thus didn't need to impute any missing data.

<POMELO TO ADD>

#### Models

We chose a Multiple Linear Regression model to make predictions on how many Uber rides there would be on a given day. We chose this model because the outcome variable is continuous and we have multiple predictors to take into consideration. Additionally, the model is easy to interpret and offers robust assumptions for our data to fit against. 

We conducted a priori analysis using correlation coefficients and exploratory data analysis to select a subset of predictors to use as independent variables in the regression model. Because our research question asks whether adverse weather has an impact on the day's number of Uber rides, we created a new variable named weekday, based on the recorded date, for which day of the week the ride occurred. We also recorded the precipitation variable into a categorical variable with two levels: one for a day with no rain, and the other for rainy days. Therefore, the final selection of independent variables are: day of the week, whether the day had rain, amount of snow, wind strength, average temperature, and borough. 

We used the VIF function and found no multicollinearity issues among the predictors. We also did not transform the variables because their distributions were approximately normal. Please see table 1.3 for more details about VIF values. 

The equation of the model is:
$$Rides = {\beta_0} + {\beta_1}Day +{\beta_2}Wind + {\beta_3}Rain  + {\beta_4}Snow + {\beta_5}Temp + {\beta_6}Borough$$
Below is the summary of our final model:

Figure 1.1

```{r, echo = FALSE}
# Create train-test partition
set.seed(2022)
# Get the training indices
train_index <- sample(1:nrow(uber15_weather), 870)
# Split the data into training and testing sets
train_data <- uber15_weather[train_index,]
test_data <- uber15_weather[-train_index,]
# Fitting the full model
full_mod <- lm(trips ~ weekday + rain + SNOW + AWND + Borough + TAVG, data = train_data)
summary(full_mod) %>% pander
```

#### Model Assessment

The model residuals seem randomly distributed around 0. The residuals appear approximately normal. And there does not seem to be any alarming leverage points. We do observe separation within our dataset having values either in the lower ranges (<20k) or in the higher ranges (>50k) as illustrated by the "Residuals vs Fitted" graph. This is likely due to the stark difference in population density across the Boroughs in NYC. We'd expect Boroughs like Manhattan that is more densely populated to have significantly more pickup rides than Queens. While we're slightly concerned about the separation, we do not think it'll largely impact the overall findings of our report, and we therefore conclude that the multiple linear regression assumptions are reasonably met for our model. 

Figure 1.2

```{r, echo = FALSE}
# Check for the assumption plots
par(mfrow = c(2,2))
plot(full_mod)
```

The model performed well in the training set, with an $R^2$ value of 0.947 and a Root Mean Squared Error of 4711.01. It does not seem to have overfit and performs just as well in the testing data set, with a Root Mean Squared Error of 4619.93. 

### Q2
```{r import data, echo=FALSE, include=FALSE}

new_weather <- subset(uber15_weather, uber15_weather$Borough != "EWR" & uber15_weather$Borough != "Unknown")

new_weather$Borough <- toupper(new_weather$Borough)

uber_merged <- read_csv("https://raw.githubusercontent.com/celisa/uber-trip-data/main/uber_merged.csv")


uber_weather_merged <- full_join(uber_merged, new_weather, by = c("DATE" = "Pickup_date", 'Borough' = 'Borough'))

keeps <- c("DATE","Borough","No. of uber trips", "PERSONS KILLED","AWND","rain", "SNOW", "TAVG")

final_df = uber_weather_merged[keeps]


final_df$killed_YN <- ifelse(final_df$"PERSONS KILLED">0, "Yes", "No")

final_df$killed_YN_binary <- ifelse(final_df$"PERSONS KILLED">0, 1, 0)

#final_df$Borough2 <- relevel(final_df$Borough, ref = "MANHATTAN") 
colnames(final_df)[3] = "ubertrips"

final_df$rain <- factor(final_df$rain)
#final_df$Borough2 <- factor(final_df$Borough2)
final_df$Borough <- factor(final_df$Borough)
final_df$killed_YN <- factor(final_df$killed_YN)
final_df$killed_YN_binary <- factor(final_df$killed_YN_binary)


#make this example reproducible

set.seed(1)

#use 70% of dataset as training set and 30% as test set
sample <- sample.split(final_df$killed_YN, SplitRatio = 0.7)
train  <- subset(final_df, sample == TRUE)
test   <- subset(final_df, sample == FALSE)


# set.seed(2)
# sample2 <- sample2.split(final_df$killed_YN, SplitRatio = 0.8)
# train2  <- subset(final_df, sample2 == TRUE)
# test2   <- subset(final_df, sample2 == FALSE)

train_logist <- glm(killed_YN ~ Borough + ubertrips + AWND + rain + SNOW + TAVG, data = train, family = "binomial" )


#train_logist2 <- glm(killed_YN ~ Borough + ubertrips + trafficcol + AWND + rain + SNOW + TAVG, data = train2, family = "binomial" )

#train_logist3 <- glm(killed_YN ~ Borough + trafficcol + AWND + rain + SNOW + TAVG, data = train, family = "binomial" )



```

#### Data
<POMELO TO ADD>

#### Models
For this question, we would like to examine contributory factors to the likelihood of people getting killed in traffic collisions. We are interested in building a predictive model to find out whether factors such as daily uber trips, variations in weather pattern or the number of daily traffic collisions contribute to the probability of people getting killed in traffic collisions. Though our outcome variable, people getting killed, is a discrete variable, this incident is most likely to either takes place or not. In other words, we will categorize at least one or more person killed as Yes or 1, and no deaths in a particular collision as No or 0. Therefore, we are treating our outcome variable as dichotomous and decided to apply logistic regression model.


#### Variable Selection
Our response variable in the data set is people getting killed from the traffic collision (Yes/No) and is labelled in the data set as `killed_YN` which is a binary variable of Yes and No. Our explanatory variables include no. of daily uber trips per Borough, `ubertrips`, and the five boroughs of New York City, `Borough`. To understand the influence of variation in weather patterns, we have also included Average daily wind, `AWND`, average daily temperature, `TAVG`, average daily snow, `SNOW`, and whether it rained on a given day, `rain`, which is a boolean data type. We used a priori variable selection approach to include the above variables in our model.

We used the VIF function to assess multicollinearity between the predictors. We found very strong multicollinearity present among daily uber trips, `ubertrips`, and the Boroughs, `Manhattan`(35.92) and `Brookylyn`(6.85), which drops significantly when the variable `ubertrips` is excluded from the model. However, we recognized the presence of multicollinearity is possibly due to the fact that there were relatively more number of daily uber pickups in `Manhattan` and `Brooklyn`, compared to other boroughs. Additionally, since `Borough` is a categorical variable while `ubertrips` is a numeric variable, the effect of multicollinearity among these predictors can be ignored. In addition, none of the other predictor variables have VIF factor over 5, suggesting very low multicollinearity among other predictors in our model.

Our data is collected between January 1, 2015 through June 30, 2015 and we used random sampling to split the dataset into 70/30 ratio between train and test data, where we will be training our model on the train data set and analyzing it's out of sample accuracy using the test data set.

#### Model Assessment
We created a model fitting equation that explains the probability of people getting killed in a traffic collision in terms of the above explanatory variables:

$$P[Y_{i} = 1 | x_{i}] = \pi_{i} $$

$$logit(\pi_{i}) = ln(\pi_{i}/1-\pi_{i}) = {\beta_0} + {\beta_1}Borough + {\beta_2}ubertrips +{\beta_3}AWND +{\beta_4}rain  + {\beta_5}SNOW + {\beta_6}TAVG $$

```{r final_project, echo = FALSE, results = 'asis', message = FALSE, warning = FALSE}

stargazer(train_logist,header=FALSE,title="Logistic Regression Models", digits = 2,type='latex',no.space = TRUE,column.sep.width = "3pt",single.row=TRUE)

```


```{r final_project2, echo = FALSE, results = 'asis', message = FALSE, warning = FALSE}
train_logistic_summary <- data.frame(exp(cbind(OR = coef(train_logist), confint(train_logist))))

kable(train_logistic_summary,col.names=c("Odds ratio","2.5%","97.5%"), format = "latex", caption = "Odds ratio and confidence intervals") %>%   kable_styling(position="center",latex_options = c("hold_position"))


# kable(modmat,row.names=TRUE,col.names=c("Odds","SE","t","p-value"),format="latex",booktabs=T,caption="SLR Model Regressing Rate onto Age") %>% 
#   kable_styling(position="center",latex_options = c("hold_position"))

```

The tables above show the summary of the logistic regression model(table 1) for "killed_YN" as the outcome variable, and table 2 shows the `Odds ratio` and `confidence interval` of the coefficients in our model(table 2). 

```{r final_project3, echo=FALSE, message = FALSE, results = "hide", fig.align = 'center', out.width = "50%", fig.show='hold'}
roc(train$killed_YN, fitted(train_logist), print.thres=0.5,print.auc = T, plot = T, legacy.axes = T)

#roc(train2$killed_YN, fitted(train_logist2), print.thres=0.5,print.auc = T, plot = T, legacy.axes = T)


```






```{r final_project4, echo = FALSE, results = 'asis', message = FALSE, warning = FALSE}
##in sample prediction

training_prediction2 <- predict(train_logist, train, type="response")
training_prediction2 <- as.factor(ifelse(training_prediction2 > 0.087, 1, 0))
confusion_new <- confusionMatrix(training_prediction2, as.factor(train$killed_YN_binary))

#out of sample prediction seed
test_prediction2 <- predict(train_logist, test, type="response")
test_prediction2 <- as.factor(ifelse(test_prediction2 > 0.087, 1, 0))
confusion_test <- confusionMatrix(test_prediction2, test$killed_YN_binary)




```

```{r final_project5, echo = FALSE, results = 'asis', message = FALSE, warning = FALSE}
confusion_mat_1 <- matrix(c(47,9, 289, 289), nrow = 2, dimnames = list(c("Pred killed", "Pred not killed"), c("Killed", "Not Killed")))

par(mfrow=c(1,1))

stargazer(confusion_mat_1, header=FALSE, type="latex", 
          no.space = TRUE,
          report = ('vcsp*'), single.row = TRUE,
          column.sep.width = "0.2pt",
          font.size = "small",
          title="Confusion Matrix(in sample)")

```

```{r final_project6, echo = FALSE, results = 'asis', message = FALSE, warning = FALSE, cache = TRUE}
confusion_mat_2 <- matrix(c(19,5, 131, 116), nrow = 2, dimnames = list(c("Pred killed", "Pred not killed"), c("Killed", "Not Killed")))
par(mfrow=c(1,1))

stargazer(confusion_mat_2, header=FALSE, type="latex", 
          no.space = TRUE,
          report = ('vcsp*'), single.row = TRUE,
          column.sep.width = "0.2pt",
          font.size = "small",
          title="Confusion Matrix(out of sample)")

```

### Roc curve and Confusion Matrices

The ROC plot above shows the performance of our logistic regression model on the sensitivity, specificity scale along with the Area under the curve(AUC) value. Our model has an AUC value of ~0.70 which implies that our model has a greater chance of correctly predicting true samples(True positive) than incorrectly predicting (false positives). In other words, the proportion of correctly classified "killed" or "not killed" is higher than the proportion of incorrectly classified "killed"/"not killed". We used the ROC curve to tune our model's predictive power to accurately predict `killed` and 'not killed` using train(in sample) and test data(out of sample).

The confusion matrix (1) which depicts in sample predictive power of the model shows that our model accurately predicted 47 out of the 56 `killed` present in the dataset, with a sensitivity (true positive rate) of ~84%. However, our model does a poor job in predicting `not killed` in the dataset, with only predicting 289 out of 578 `not killed` present in the dataset. This gives our model a specificity rate of 50% only, suggesting that our model predicts people killed in the traffic collision far better than people not getting killed in the collision.

The confusion matrix (2) shows our model's out of sample predictive power, where our model accurately predicted 19 off the 24 `killed` accurately, while only accurately predicting 116 out of 247 `not killed` present in the dataset. This gives our model a sensitivity rate of ~80% and a specificity rate of ~47%. Using the out of sample dataset, we noticed our model performance is consistent with in sample predictive performance with accurately predicting more kills than not kills in the traffic collision.

## Results
Based on our results, we learned that the weather, day of the week, and Borough explain over 90% of the variation within the model. With the exception of temperature, weather conditions are less significant for determining the number of Uber pickup rides contrary to our initial belief. As illustrated by the EDA, the pickup Borough has the most explanatory power in terms of predicting the number of pick-ups. On average, Manhattan and Brooklyn have 54,625 and 11,555 more Uber Rides than that of Bronx respectively as illustrated in Figure 1.1 in the Models section. We also learned that on Mondays, on average we'd expect ~1795 less Uber pick-ups compared to Sunday. On Thu, Fri and Sat we'd expect there to be more Uber pick-ups compared to that of Sunday on average. Please see below graph that illustrates the number of pickups by weekday by Borough: 

```{r, echo = FALSE}
ggplot(uber15_weather, aes(fill=Borough, y=trips, x=weekday)) + 
    geom_bar(position="stack", stat="identity") + labs(x = "Day of the Week", y = "Number of Trips", title = "Number of Uber Trips By Day of Week and Borough")
```
Supported by our model summary, the above graph illustrates that we have the most pickups during the weekends with majority of the rides taking place in Manhattan.

From the logistic regression result, we noticed that `Brooklyn` and `Queens` are positively correlated, and while `Manhattan` and `Staten Island` are negatively correlated with the outcome variable, with `Bronx` being the reference state. Compared to `Bronx`, for every collision that happens in `Brooklyn` and `Queens`, the odds of getting killed is increased by 70% and 40% respectively, while in `Manhattan`, `Staten Island`, the odds of getting killed is lowered by 37%, 80% respectively. This implies that there is a higher likelihood of getting killed in the traffic collision in `Brooklyn` and `Queens`, compared to `Manhattan` and `Staten Island`. Variables `Daily Average Wind (AWND)` and `Daily Average Temperature(TAVG)` slightly influence the likelihood of getting killed, such that for every unit or degrees increase in Average Wind or Temperature, the odds of getting killed in the traffic collision increases by 1.5% and 1.4% respectively. In contrast, when there is rain in New York City, the odds of traffic collision deaths get reduced by 10%. This makes sense because when there is rain, people tend to be less likely on the streets and the motorists tend to be drive slower reducing the risks of getting killed in the traffic collision. We also noticed that the number of daily uber trips does not have any impact on the traffic collision deaths. To be precise, for every increase in the number of daily uber trips, the odds of getting killed increases by 0.02%, which can be considered negligible.

However, it is worth mentioning that only the variable `Staten Island` is statistically significant with the outcome variable, while every other predictors in the model are not statistically significant with our outcome variable. This implies none of our predictors do a good job in explaining our outcome variable, `Killed_YN`. This is partially due to the fact that we only roughly 900 observations in our dataset and the dataset is constrained within the first six months of the year 2015. This definitely possesses a limitation on the predictive power of using this model to predict traffic collision deaths. In addition, this also suggests that we need to further look into independent variables which could explain our model better.


<POMELO TO ADD A GRAPH>

## Conclusion
In this analysis we investigated whether weather conditions impact the number of Uber pick-up rides and whether Uber pick-up rides increase the likelihood of traffic collision deaths in NYC. Factors like Pick-up Borough, and day of the week have the largest impact on the number of Uber rides in NYC. Contrary to our initial belief, with the exception of temperature, weather conditions do not significantly impact the number of Uber rides on a given day.  <POMELO - ADD>

### Limitations
During our model assessment, we observed separation of low and high values within the data, which could potentially be mitigated with data transformations or by simply creating two separate models for low populated areas (Bronx, Queens, Staten Island) and high populated areas (Manhattan and Brooklyn). Additionally, our dataset does not capture seasonality as we do not have data for the months of August - December. We also did not control for other factors like public transit availability and Borough population that could also influence the number of pickup rides in a given area. We observed a small degree of multicollinearity for our logistic regression model, which could be mitigated by limiting the number of variables in the model. The dataset with traffic collisions deaths was highly imbalanced due to the nature of data, which resulted in low model accuracy. 

### Future Work
In the future, it would be interesting to expand the research by collecting more data on other months and years, and including more information in our datasets such as public transit availability and population to account for factors that also influence the number of pickup rides. We would also want to create synthetic datasets using techniques like SMOTE to account for imbalanced datasets. 

\newpage

## Appendix

Table 1.1

``` {r figure 1.1 - table 1, echo=FALSE}
sum_uber_data = uber15_weather[c("trips","PRCP","SNOW","TAVG")]
summary(sum_uber_data) %>% kable
```

Table 1.2
``` {r weather dictionary, echo=FALSE}
weather_dict <- read.csv('https://raw.githubusercontent.com/celisa/uber-trip-data/main/weather_dict.csv')
weather_dict %>% kable()
```

Table 1.3
```{r multicollinearity, echo = FALSE}
# Check for multicolinearity
vif(full_mod) %>% kable
```
In addition to a priori variable selection, we also performed a backward selection to complement our decision-making. It appears that for the most part our Priori variable selection aligns with the backward selection. 
```{r, echo = FALSE}
# Perform backward selection
subset_mod <- regsubsets(trips ~ weekday + rain + SNOW + AWND + Borough + TAVG, data = train_data,
                         method = "backward")
summary(subset_mod)
plot(subset_mod, scale = "r2")
```

\newpage
## References
Fivethirtyeight. (n.d.). Uber trip data from NYC's Taxi & Limousine Commission. GitHub. Retrieved November 29, 2022, from https://github.com/fivethirtyeight/uber-tlc-foil-response

NYPD. (2017, March 9). Vehicle collisions in NYC, 2015-Present. Kaggle. Retrieved November 29, 2022, from https://www.kaggle.com/datasets/nypd/vehicle-collisions

Weather. National Oceanic and Atmospheric Administration. (n.d.). Retrieved November 29, 2022, from https://www.noaa.gov/weather
